{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Narratives to Explain<br>AI Models\"\n",
        "subtitle: \"Antwerp Center on Responsible AI<br>Research Day 2025\"\n",
        "author: \"<br>Mateusz Cedro\"\n",
        "format:\n",
        "  revealjs: \n",
        "    css: styles.css\n",
        "    theme: [default]\n",
        "    slide-number: true\n",
        "    touch: true\n",
        "    scrollable: true\n",
        "    chalkboard: \n",
        "      buttons: false\n",
        "    logo: images/ua_logo.jpg\n",
        "    footer: \"XAI Narratives -- Mateusz Cedro -- ACRAI Research Day 2025\"\n",
        "---"
      ],
      "id": "e8728cfa"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```{css, echo=FALSE}\n",
        ".reveal {\n",
        "  font-size: 24px;\n",
        "  line-height: 1.6!important;\n",
        "}\n",
        "code {\n",
        "  font-size: 18px!important;\n",
        "  line-height: 1.2!important;\n",
        "}\n",
        "pre {\n",
        "  line-height: 1.2!important;\n",
        "}\n",
        "```\n",
        "\n",
        "\n",
        "# Paper of the day\n",
        "\n",
        "## A Unified Approach to Interpreting Model Predictions\n",
        "\n",
        "- In this course, you will learn about the main methods and tools related to XAI, but also (and this may be unique) about selected papers and researchers.\n",
        "- That's why we will start this and the next classes with a brief presentation of a high-impact article from the XAI field + few words about the author of this article.\n",
        "- Today we are talking about Shapley values, so the article of the day will be the 2017 SHAP method article.\n",
        "- It will be about the paper [A Unified Approach to Interpreting Model Predictions](https://papers.nips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html)\n",
        "\n",
        "<p><img src=\"images/shap_v_01.png\" width=\"100%\"/></p>\n",
        "\n",
        "\n",
        "## SHAP paper in numbers\n",
        "\n",
        "- This article is really exceptional, it will soon exceed 10,000 citations which is an amazing achievement.\n",
        "- The article has several strong points, which we will talk about later today, one of which is the available software that allows you to easily use the described method\n",
        "- This software is a shap library, which on GitHub has skyrocketing numbers of stars and downloads\n",
        "\n",
        "<p><img src=\"images/shap_v_01.png\" width=\"100%\"/></p>\n",
        "\n",
        "<p><img src=\"images/shap_v_01.png\" width=\"100%\"/></p>\n",
        "\n",
        "\n",
        "## Why SHAP?\n",
        "\n",
        "- Shapley values are currently the most popular technique for model explanations (almost in each category: local, global, model agnostic, model specific...)\n",
        "- if you remember only one method after this course, let it be the SHAP\n",
        "- It has more than five years of development. In the list of major XAI methods, you can also find its various extensions like ShapleyFlow or ASV (more about them later)\n",
        "- figures below are from the paper [Explainable AI Methods - A Brief Overview](https://link.springer.com/chapter/10.1007/978-3-031-04083-2_2)\n",
        "\n",
        "<p><img src=\"images/shap_v_01.png\" width=\"100%\"/></p>\n",
        "\n",
        "<p><img src=\"images/shap_v_01.png\" width=\"100%\"/></p>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## XAI pyramid\n",
        "\n",
        "- We will use an XAI pyramid to present new methods during this course. \n",
        "- Today we will mainly talk about the method of local explanations - Shapley values, which for a single observation determines the importance of variables.\n",
        "\n",
        "<p><img src=\"images/shap_v_01.png\" width=\"100%\"/></p>\n",
        "\n",
        "- This is one of the three fundamental methods of explaining the behaviour of predictive models.\n",
        "- The following three panels introduce these three concepts; we will return to them in one week and two weeks.\n",
        "- SHAP corresponds to panel C. We try to explain the behaviour of the model by decomposing the distance between this particular prediction and the average prediction of the model.\n",
        "\n",
        "<p><img src=\"images/shap_v_01.png\" width=\"100%\"/></p>\n",
        "\n",
        "\n",
        "\n",
        "# Shapley values\n",
        "\n",
        "\n",
        "## Notation\n",
        "\n",
        "- We have set of $P = \\{1, ..., p\\}$ players\n",
        "- For each coalition, i.e. subset $S\t\\subseteq P$ we can calculate the payout $v(S)$ and $v(\\{\\varnothing\\}) = 0$\n",
        "- We want to fairly distribute the payout $v(P)$\n",
        "- Optimal attribution for player $i\\in P$ will be denoted as $\\phi_i$ \n",
        "\n",
        "## Motivational example 1/3\n",
        "\n",
        "How to divide the reward?\n",
        "\n",
        "- Three parties A, B and C took part in the election. \n",
        "- As a result of the election, parties A and B each have 49% representation in the parliament and party C has 2% representation. \n",
        "- Let's assume that A and C formed a government. \n",
        "- How to fairly divide the prize (ministries)? \n",
        "- What share of the prize should party C have?\n",
        "\n",
        "\n",
        "Note that any two parties can form a government.  In that case, should the prize for C be equal to or less than that for A?\n",
        "\n",
        "<p><img src=\"images/shap_v_01.png\" width=\"100%\"/></p>\n"
      ],
      "id": "51fc7118"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}